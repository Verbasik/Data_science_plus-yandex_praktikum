{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7eae4a02",
      "metadata": {
        "id": "7eae4a02"
      },
      "source": [
        "### –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ BERT ü§ñüìö\n",
        "\n",
        "**–¶–µ–ª—å** üéØ\n",
        "\n",
        "–¶–µ–ª—å—é –ø—Ä–æ–µ–∫—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ —Å–≤—è–∑–∫–∏ —Å –º–æ–¥–µ–ª—å—é —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–º BERT. –ó–∞–¥–∞—á–∞ –º–æ–¥–µ–ª–∏ ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —Ç–æ–∫—Å–∏—á–∏–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π (–∫–ª–∞—Å—Å 1) –∏–ª–∏ –∂–µ –Ω–µ—Ç (–∫–ª–∞—Å—Å 0), —Å —Ü–µ–ª—å—é –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ F1 –Ω–µ –º–µ–Ω–µ–µ 0.75.\n",
        "\n",
        "**–û–ø–∏—Å–∞–Ω–∏–µ** üß™üî¨\n",
        "\n",
        "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é.\n",
        "\n",
        "**–ó–∞–¥–∞—á–∏**\n",
        "\n",
        "–ü—Ä–æ–µ–∫—Ç –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞—á–∏–Ω–∞—è —Å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∏ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –¥–æ –æ–±—É—á–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏. –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ ‚Äî —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ BERT –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–æ–¥–µ–ª–∏ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ—Ü–µ—Å—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —Å–ª–µ–¥—É—é—â–∏–µ —ç—Ç–∞–ø—ã:\n",
        "\n",
        "**–≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**\n",
        "\n",
        "- –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –≤–∫–ª—é—á–∞—è –∑–∞–≥—Ä—É–∑–∫—É, –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö;\n",
        "- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∏—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç —Ç–µ–Ω–∑–æ—Ä–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–æ–¥–µ–ª—å—é;\n",
        "- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ —Å —É—á–µ—Ç–æ–º –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —á–µ—Å—Ç–Ω–æ–µ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "**–≠—Ç–∞–ø 2: –≠—Ç–∞–ø 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ:**\n",
        "\n",
        "  - –û–±—É—á–µ–Ω–∏–µ PyTorch model;\n",
        "  - –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç—Ä–∏–∫—É F1-–º–µ—Ä—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –µ—ë —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ –æ–±–æ–±—â–µ–Ω–∏—é.\n",
        "\n",
        "**–≠—Ç–∞–ø 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:**\n",
        "\n",
        "- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –µ—ë —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π;\n",
        "\n",
        "- –í—ã–≤–æ–¥\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x-emLmj8rOWf",
      "metadata": {
        "id": "x-emLmj8rOWf"
      },
      "source": [
        "## **–≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3068a0b-0c82-4f46-9ba5-ee01fd9a6138",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:23:14.382823Z",
          "iopub.status.busy": "2024-06-01T12:23:14.381428Z",
          "iopub.status.idle": "2024-06-01T12:23:44.213470Z",
          "shell.execute_reply": "2024-06-01T12:23:44.212172Z",
          "shell.execute_reply.started": "2024-06-01T12:23:14.382783Z"
        },
        "id": "d3068a0b-0c82-4f46-9ba5-ee01fd9a6138",
        "outputId": "5a98ebeb-cb26-4d3a-9e4c-5056bee3c937",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b5b5be-9a53-4263-87bb-b74ade59e962",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:24:10.289967Z",
          "iopub.status.busy": "2024-06-01T12:24:10.288264Z",
          "iopub.status.idle": "2024-06-01T12:24:14.499847Z",
          "shell.execute_reply": "2024-06-01T12:24:14.498617Z",
          "shell.execute_reply.started": "2024-06-01T12:24:10.289929Z"
        },
        "id": "b3b5b5be-9a53-4263-87bb-b74ade59e962",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "# –ù–∞—É—á–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ–π—Ä–æ–Ω–Ω—ã–º–∏ —Å–µ—Ç—è–º–∏\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "\n",
        "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è PyTorch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6f11e2-afe5-4baa-b31d-63a3e96497b6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:36:11.259383Z",
          "iopub.status.busy": "2024-06-01T12:36:11.258084Z",
          "iopub.status.idle": "2024-06-01T12:36:12.334407Z",
          "shell.execute_reply": "2024-06-01T12:36:12.333227Z",
          "shell.execute_reply.started": "2024-06-01T12:36:11.259325Z"
        },
        "id": "5c6f11e2-afe5-4baa-b31d-63a3e96497b6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# –°–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è (hidden states) - —ç—Ç–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ –≤–æ –≤—Ä–µ–º—è –ø—Ä—è–º–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞.\n",
        "# –≠—Ç–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ–∑–≤–æ–ª—è—é—Ç –ø–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —Ñ–æ—Ä–º–∏—Ä—É–µ–º–æ–µ –º–æ–¥–µ–ª—å—é –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ.\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å BERT.\n",
        "bert = AutoModelForSequenceClassification.from_pretrained(\"JungleLee/bert-toxic-comment-classification\", output_hidden_states=True).to(device)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ BERT.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"JungleLee/bert-toxic-comment-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wZ5oQVScD5j4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:24:53.441469Z",
          "iopub.status.busy": "2024-06-01T12:24:53.439929Z",
          "iopub.status.idle": "2024-06-01T12:24:53.476691Z",
          "shell.execute_reply": "2024-06-01T12:24:53.475313Z",
          "shell.execute_reply.started": "2024-06-01T12:24:53.441432Z"
        },
        "id": "wZ5oQVScD5j4",
        "outputId": "e6f5bc74-78e6-4949-9cc9-5806b5751c03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HJzS1HiKDwiD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:24:56.462819Z",
          "iopub.status.busy": "2024-06-01T12:24:56.461364Z",
          "iopub.status.idle": "2024-06-01T12:24:56.478957Z",
          "shell.execute_reply": "2024-06-01T12:24:56.477912Z",
          "shell.execute_reply.started": "2024-06-01T12:24:56.462768Z"
        },
        "id": "HJzS1HiKDwiD",
        "outputId": "42ba3ccb-a09b-47f2-f3f7-b9083ae14c6d",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='JungleLee/bert-toxic-comment-classification', vocab_size=30522, model_max_length=256, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "463240f3-78e1-4bf5-836f-010ab1de7a61",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:22.675413Z",
          "iopub.status.busy": "2024-06-01T12:25:22.674545Z",
          "iopub.status.idle": "2024-06-01T12:25:23.862795Z",
          "shell.execute_reply": "2024-06-01T12:25:23.861644Z",
          "shell.execute_reply.started": "2024-06-01T12:25:22.675359Z"
        },
        "id": "463240f3-78e1-4bf5-836f-010ab1de7a61",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
        "df = pd.read_csv('/home/jupyter/datasphere/project/toxic_comments.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7366c8-2efb-413b-bfe1-b0d2d3e45613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:26.427025Z",
          "iopub.status.busy": "2024-06-01T12:25:26.425777Z",
          "iopub.status.idle": "2024-06-01T12:25:26.509057Z",
          "shell.execute_reply": "2024-06-01T12:25:26.507684Z",
          "shell.execute_reply.started": "2024-06-01T12:25:26.426986Z"
        },
        "id": "9d7366c8-2efb-413b-bfe1-b0d2d3e45613",
        "outputId": "e0ee1f39-f8d3-46e1-cefb-eba0a5e16c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159292 entries, 0 to 159291\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   Unnamed: 0  159292 non-null  int64 \n",
            " 1   text        159292 non-null  object\n",
            " 2   toxic       159292 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 3.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7cdc9c1-1b85-40a8-b1a6-bb3494172276",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:28.590285Z",
          "iopub.status.busy": "2024-06-01T12:25:28.588441Z",
          "iopub.status.idle": "2024-06-01T12:25:28.625199Z",
          "shell.execute_reply": "2024-06-01T12:25:28.624105Z",
          "shell.execute_reply.started": "2024-06-01T12:25:28.590225Z"
        },
        "id": "a7cdc9c1-1b85-40a8-b1a6-bb3494172276",
        "outputId": "6657be46-8b37-41d7-a893-00a546ff0ffc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text  toxic\n",
              "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1           1  D'aww! He matches this background colour I'm s...      0\n",
              "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4           4  You, sir, are my hero. Any chance you remember...      0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l2W8D96NUT36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:30.202377Z",
          "iopub.status.busy": "2024-06-01T12:25:30.201130Z",
          "iopub.status.idle": "2024-06-01T12:25:30.235192Z",
          "shell.execute_reply": "2024-06-01T12:25:30.233949Z",
          "shell.execute_reply.started": "2024-06-01T12:25:30.202333Z"
        },
        "id": "l2W8D96NUT36",
        "outputId": "20a0607e-89f4-4b44-fa01-67f8d20fc744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Explanation\\nWhy the edits made under my usern...\n",
              "1         D'aww! He matches this background colour I'm s...\n",
              "2         Hey man, I'm really not trying to edit war. It...\n",
              "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4         You, sir, are my hero. Any chance you remember...\n",
              "                                ...                        \n",
              "159287    \":::::And for the second time of asking, when ...\n",
              "159288    You should be ashamed of yourself \\n\\nThat is ...\n",
              "159289    Spitzer \\n\\nUmm, theres no actual article for ...\n",
              "159290    And it looks like it was actually you who put ...\n",
              "159291    \"\\nAnd ... I really don't think you understand...\n",
              "Name: text, Length: 159292, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A8MIN99rUE6z",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:32.296428Z",
          "iopub.status.busy": "2024-06-01T12:25:32.295303Z",
          "iopub.status.idle": "2024-06-01T12:25:34.727498Z",
          "shell.execute_reply": "2024-06-01T12:25:34.726340Z",
          "shell.execute_reply.started": "2024-06-01T12:25:32.296392Z"
        },
        "id": "A8MIN99rUE6z"
      },
      "outputs": [],
      "source": [
        "# –ò–∑–±–∞–≤–∏–º—Å—è –æ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ\n",
        "df['text'] = df['text'].apply(lambda x: \" \".join(re.sub(r\"[^a-zA-Z ]\", ' ', x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WeSgTHXQVbBA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:35.781932Z",
          "iopub.status.busy": "2024-06-01T12:25:35.780536Z",
          "iopub.status.idle": "2024-06-01T12:25:35.804032Z",
          "shell.execute_reply": "2024-06-01T12:25:35.803014Z",
          "shell.execute_reply.started": "2024-06-01T12:25:35.781884Z"
        },
        "id": "WeSgTHXQVbBA",
        "outputId": "6759896a-d6f6-4384-84c3-3cee89358dcd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Explanation Why the edits made under my userna...\n",
              "1         D aww He matches this background colour I m se...\n",
              "2         Hey man I m really not trying to edit war It s...\n",
              "3         More I can t make any real suggestions on impr...\n",
              "4         You sir are my hero Any chance you remember wh...\n",
              "                                ...                        \n",
              "159287    And for the second time of asking when your vi...\n",
              "159288    You should be ashamed of yourself That is a ho...\n",
              "159289    Spitzer Umm theres no actual article for prost...\n",
              "159290    And it looks like it was actually you who put ...\n",
              "159291    And I really don t think you understand I came...\n",
              "Name: text, Length: 159292, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aFEtX-1XWL_7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:39.634741Z",
          "iopub.status.busy": "2024-06-01T12:25:39.633756Z",
          "iopub.status.idle": "2024-06-01T12:25:39.662965Z",
          "shell.execute_reply": "2024-06-01T12:25:39.661900Z",
          "shell.execute_reply.started": "2024-06-01T12:25:39.634691Z"
        },
        "id": "aFEtX-1XWL_7",
        "outputId": "c42dcf94-e16f-4bb3-acca-6b48742343db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    143106\n",
              "1     16186\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0    89.84%\n",
              "1    10.16%\n",
              "Name: toxic, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "display(df['toxic'].value_counts())\n",
        "df['toxic'].value_counts(normalize=True).map('{:.2%}'.format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_Ua1Ac1zWRq4",
      "metadata": {
        "id": "_Ua1Ac1zWRq4"
      },
      "source": [
        "- –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, —Å–æ—Å—Ç–æ—è—Ç –∏–∑ 159571 —Å—Ç—Ä–æ–∫ –∏ 2 —Å—Ç–æ–ª–±—Ü–æ–≤;\n",
        "- –°—Ç–æ–ª–±–µ—Ü toxic —è–≤–ª—è–µ—Ç—Å—è —Ü–µ–ª–µ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–º —Å –≤—ã—Ä–∞–∂–µ–Ω—ã–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º –∫–ª–∞—Å—Å–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hQc8ab2xhRd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:25:43.534360Z",
          "iopub.status.busy": "2024-06-01T12:25:43.533066Z",
          "iopub.status.idle": "2024-06-01T12:25:44.140188Z",
          "shell.execute_reply": "2024-06-01T12:25:44.139138Z",
          "shell.execute_reply.started": "2024-06-01T12:25:43.534313Z"
        },
        "id": "hQc8ab2xhRd3",
        "outputId": "2ace913c-f087-4426-cb49-7e8330c9225e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1403"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# –î–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª–∏–Ω–æ–π, –Ω–µ –±–æ–ª—å—à–µ 512 —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ—ç—Ç–æ–º—É —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—é, –∫–∞–∫–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≤ train_df\n",
        "seq_len_train = [len(str(i).split()) for i in df['text']]\n",
        "max_seq_len = max(seq_len_train)\n",
        "max_seq_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62pE1OvlYw8r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:29:17.542242Z",
          "iopub.status.busy": "2024-06-01T12:29:17.540508Z",
          "iopub.status.idle": "2024-06-01T12:29:17.624092Z",
          "shell.execute_reply": "2024-06-01T12:29:17.622978Z",
          "shell.execute_reply.started": "2024-06-01T12:29:17.542182Z"
        },
        "id": "62pE1OvlYw8r",
        "outputId": "39600ec7-7405-4980-c162-8efc8ee7348a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced Train DataFrame Class Distribution:\n",
            "0    15000\n",
            "1    15000\n",
            "Name: toxic, dtype: int64\n",
            "Validation DataFrame Class Distribution:\n",
            "0    5388\n",
            "1     612\n",
            "Name: toxic, dtype: int64\n",
            "Test DataFrame Class Distribution:\n",
            "0    5432\n",
            "1     568\n",
            "Name: toxic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# –û—Ç–±–∏—Ä–∞–µ–º 6000 —Å—Ç—Ä–æ–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
        "df_valid = df.sample(n=6000, random_state=42)\n",
        "\n",
        "# –£–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ DataFrame\n",
        "df = df.drop(df_valid.index)\n",
        "\n",
        "# –û—Ç–±–∏—Ä–∞–µ–º 6000 —Å—Ç—Ä–æ–∫ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
        "df_test = df.sample(n=6000, random_state=42)\n",
        "\n",
        "# –£–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ DataFrame\n",
        "df = df.drop(df_test.index)\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞\n",
        "min_count = 15000\n",
        "\n",
        "# –°—ç–º–ø–ª–∏—Ä—É–µ–º –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø–æ min_count —Å—Ç—Ä–æ–∫\n",
        "df_class_0 = df[df['toxic'] == 0].sample(n=min_count, random_state=42)\n",
        "df_class_1 = df[df['toxic'] == 1].sample(n=min_count, random_state=42)\n",
        "\n",
        "# –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—ç–º–ø–ª—ã –≤ –æ–¥–∏–Ω DataFrame\n",
        "df_train = pd.concat([df_class_0, df_class_1])\n",
        "\n",
        "# –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª—é–±—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ—Ä—è–¥–∫–æ–≤—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "print(\"Balanced Train DataFrame Class Distribution:\")\n",
        "print(df_train['toxic'].value_counts())\n",
        "\n",
        "print(\"Validation DataFrame Class Distribution:\")\n",
        "print(df_valid['toxic'].value_counts())\n",
        "\n",
        "print(\"Test DataFrame Class Distribution:\")\n",
        "print(df_test['toxic'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q30HI5uLwATm",
      "metadata": {
        "id": "q30HI5uLwATm"
      },
      "source": [
        "### **–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ —Ç–æ–∫–µ–Ω–µ–∑–∞—Ü–∏–∏ –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤**\n",
        "\n",
        "–ü—É—Å—Ç—å $T$ ‚Äî —Ç–µ–∫—Å—Ç, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ —Ñ—É–Ω–∫—Ü–∏—è $ g: T $ to ${T_i}$, –≥–¥–µ ${T_i}$ ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ $T$.\n",
        "\n",
        "**–ü—Ä–∏–º–µ—Ä:**\n",
        "\n",
        "$$ g(\\text{–≠—Ç–æ –ø—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞}) = [\\text{–≠—Ç–æ}, \\text{–ø—Ä–∏–º–µ—Ä}, \\text{—Ç–µ–∫—Å—Ç–∞}] $$\n",
        "\n",
        "### 1. –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "–ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ $ T $ –∏–∑ —Å–ª–æ–≤ $ \\{w_1, w_2, \\ldots, w_n\\} $. –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω $ w_i $ –≤ –µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —á–∏—Å–ª–æ–≤–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä $ t_i $.\n",
        "\n",
        "* ##### $T = \\{w_1, w_2, \\ldots, w_n\\} \\rightarrow \\{t_1, t_2, \\ldots, t_n\\}$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $T$ ‚Äî —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞;\n",
        "- $w_i$ ‚Äî —Å–ª–æ–≤–æ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ;\n",
        "- $t_i$ ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —á–∏—Å–ª–æ–≤–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–ª–æ–≤–∞ $w_i$.\n",
        "\n",
        "### 2. –≠–º–±–µ–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω–æ–≤\n",
        "\n",
        "–ö–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω $t_i$ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ –≤–µ–∫—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ $d$ —Å –ø–æ–º–æ—â—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤–æ–π –º–∞—Ç—Ä–∏—Ü—ã $E \\in \\mathbb{R}^{|V| \\times d}$, –≥–¥–µ $|V|$ ‚Äî —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è. –≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ $t_i$ –æ–±–æ–∑–Ω–∞—á–∏–º –∫–∞–∫ $e_i$.\n",
        "\n",
        "* ##### $e_i = E[t_i]$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $E$ ‚Äî —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–º $|V| \\times d$;\n",
        "- $e_i$ ‚Äî —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω–∞ $t_i$;\n",
        "- $t_i$ ‚Äî –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–∫–µ–Ω–∞ $i$.\n",
        "\n",
        "### 3. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
        "\n",
        "–î–ª—è —É—á–µ—Ç–∞ –ø–æ—Ä—è–¥–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ $i$ –æ–±–æ–∑–Ω–∞—á–∏–º –∫–∞–∫ $p_i$. –ò—Ç–æ–≥–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ $i$ –±—É–¥–µ—Ç $e_i'$.\n",
        "\n",
        "* ##### $e_i' = e_i + p_i$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $e_i$ ‚Äî —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω–∞ $i$;\n",
        "- $p_i$ ‚Äî –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ $i$;\n",
        "- $e_i'$ ‚Äî –∏—Ç–æ–≥–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω–∞ $i$.\n",
        "\n",
        "–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ $p_i$ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∏–Ω—É—Å–æ–∏–¥–∞–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π:\n",
        "\n",
        "* ##### $p_{i,2k} = \\sin\\left(\\frac{i}{10000^{2k/d}}\\right)$\n",
        "* ##### $p_{i,2k+1} = \\cos\\left(\\frac{i}{10000^{2k/d}}\\right)$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $p_{i,2k}$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏–Ω—É—Å–æ–∏–¥–∞–ª—å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —á—ë—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏;\n",
        "- $p_{i,2k+1}$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –Ω–µ—á—ë—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏;\n",
        "- $i$ ‚Äî –ø–æ–∑–∏—Ü–∏—è —Ç–æ–∫–µ–Ω–∞;\n",
        "- $k$ ‚Äî –∏–Ω–¥–µ–∫—Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞;\n",
        "- $d$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞.\n",
        "\n",
        "### 4. Self-Attention\n",
        "\n",
        "–ö–∞–∂–¥—ã–π —Å–ª–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –≤–∫–ª—é—á–∞–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º self-attention. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ $i$ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç—Ä–∏ –≤–µ–∫—Ç–æ—Ä–∞: –∑–∞–ø—Ä–æ—Å (query) $Q_i$, –∫–ª—é—á (key) $K_i$ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ (value) $V_i$, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—É—á–∞—é—Ç—Å—è –ø—É—Ç–µ–º –ª–∏–Ω–µ–π–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ $e_i'$.\n",
        "\n",
        "* ##### $Q_i = W_Q e_i'$\n",
        "* ##### $K_i = W_K e_i'$\n",
        "* ##### $V_i = W_V e_i'$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $Q_i$ ‚Äî –∑–∞–ø—Ä–æ—Å —Ç–æ–∫–µ–Ω–∞ $i$;\n",
        "- $K_i$ ‚Äî –∫–ª—é—á —Ç–æ–∫–µ–Ω–∞ $i$;\n",
        "- $V_i$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ $i$;\n",
        "- $W_Q, W_K, W_V$ ‚Äî –æ–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–æ–≤—ã–µ –º–∞—Ç—Ä–∏—Ü—ã —Ä–∞–∑–º–µ—Ä–æ–º $d \\times d_k$;\n",
        "- $e_i'$ ‚Äî –∏—Ç–æ–≥–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–æ–∫–µ–Ω–∞ $i$.\n",
        "\n",
        "Attention score –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏ $i$ –∏ $j$ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫:\n",
        "\n",
        "* ##### $\\text{attention}(Q_i, K_j) = \\frac{\\exp(Q_i \\cdot K_j / \\sqrt{d_k})}{\\sum_{j=1}^{n} \\exp(Q_i \\cdot K_j / \\sqrt{d_k})}$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $\\text{attention}(Q_i, K_j)$ ‚Äî –≤–µ—Å –≤–Ω–∏–º–∞–Ω–∏—è –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏ $i$ –∏ $j$;\n",
        "- $Q_i \\cdot K_j$ ‚Äî —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ $Q_i$ –∏ $K_j$;\n",
        "- $d_k$ ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∫–ª—é—á–µ–π.\n",
        "\n",
        "–ò—Ç–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ $z_i$ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ $i$ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π $V_j$.\n",
        "\n",
        "* ##### $z_i = \\sum_{j=1}^{n} \\text{attention}(Q_i, K_j) V_j$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $z_i$ ‚Äî –∏—Ç–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ $i$;\n",
        "- $V_j$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ $j$.\n",
        "\n",
        "### 5. –°–ª–æ–∏ Feed-Forward\n",
        "\n",
        "–ü–æ—Å–ª–µ —Å–ª–æ—è self-attention —Ä–µ–∑—É–ª—å—Ç–∞—Ç $z_i$ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏.\n",
        "\n",
        "* ##### $\\text{FFN}(z_i) = W_2 \\sigma(W_1 z_i + b_1) + b_2$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $\\text{FFN}(z_i)$ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è $z_i$ —á–µ—Ä–µ–∑ feed-forward —Å–ª–æ–∏;\n",
        "- $W_1, W_2$ ‚Äî –æ–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–æ–≤—ã–µ –º–∞—Ç—Ä–∏—Ü—ã;\n",
        "- $b_1, b_2$ ‚Äî —Å–º–µ—â–µ–Ω–∏—è (bias);\n",
        "- $\\sigma$ ‚Äî –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, ReLU).\n",
        "\n",
        "### 6. –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è.\n",
        "\n",
        "* ##### $h_i^{(l+1)} = \\text{LayerNorm}(z_i + \\text{FFN}(z_i))$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $h_i^{(l+1)}$ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ $i$ –Ω–∞ —Å–ª–æ–µ $l+1$;\n",
        "- $\\text{LayerNorm}$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.\n",
        "\n",
        "### 7. –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º\n",
        "\n",
        "–ü–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —á–µ—Ä–µ–∑ –≤—Å–µ —Å–ª–æ–∏, –ø–æ–ª—É—á–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–ª–æ–µ $h_i^{(L)}$. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–µ–≥–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç, –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º.\n",
        "\n",
        "* ##### $\\text{embedding} = \\frac{1}{n} \\sum_{i=1}^{n} h_i^{(L)}$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $\\text{embedding}$ ‚Äî –∏—Ç–æ–≥–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞;\n",
        "- $n$ ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤;\n",
        "- $h_i^{(L)}$ ‚Äî —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ $i$ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–ª–æ–µ $L$.\n",
        "\n",
        "### 8. –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –Ω–∞ CPU –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ numpy\n",
        "\n",
        "–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π –≤–µ–∫—Ç–æ—Ä –ø–µ—Ä–µ–º–µ—â–∞–µ—Ç—Å—è –Ω–∞ CPU –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ –º–∞—Å—Å–∏–≤ numpy –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "* ##### $\\text{embedding\\_numpy} = \\text{embedding}.cpu().numpy()$\n",
        "\n",
        "–≥–¥–µ:\n",
        "- $\\text{embedding\\_numpy}$ ‚Äî –∏—Ç–æ–≥–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "crEmh7PA0e0m",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:29:40.281572Z",
          "iopub.status.busy": "2024-06-01T12:29:40.280006Z",
          "iopub.status.idle": "2024-06-01T12:29:40.325868Z",
          "shell.execute_reply": "2024-06-01T12:29:40.324491Z",
          "shell.execute_reply.started": "2024-06-01T12:29:40.281534Z"
        },
        "id": "crEmh7PA0e0m"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(text, tokenizer, model, device, max_length=512):\n",
        "    \"\"\"\n",
        "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–µ–∫—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É—è –º–æ–¥–µ–ª—å RoBERTa.\n",
        "\n",
        "    Description:\n",
        "        –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç, —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –≤ –º–æ–¥–µ–ª—å RoBERTa.\n",
        "        –í–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è —Å—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π.\n",
        "\n",
        "    Args:\n",
        "        text (str): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
        "        tokenizer (RobertaTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –º–æ–¥–µ–ª–∏ RoBERTa.\n",
        "        model (RobertaModel): –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å RoBERTa.\n",
        "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU) –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "        max_length (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 512).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: –°—Ä–µ–¥–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–µ–∫—Å—Ç–∞.\n",
        "    \"\"\"\n",
        "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–µ–∑–∞–Ω–∏–µ–º, –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n",
        "\n",
        "    # –ü–µ—Ä–µ–Ω–æ—Å —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏ —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏\n",
        "    with torch.no_grad():\n",
        "        # –ü—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å RoBERTa –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—ã—Ö–æ–¥–æ–≤\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è –º–æ–¥–µ–ª–∏\n",
        "    hidden_states = outputs.hidden_states[-1]\n",
        "\n",
        "    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º\n",
        "    return hidden_states.mean(dim=1).cpu().numpy()\n",
        "\n",
        "def process_short_text(text, tokenizer, model, device):\n",
        "    \"\"\"\n",
        "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–æ–π –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n",
        "\n",
        "    Description:\n",
        "        –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–æ–π –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤, —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –µ–≥–æ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏,\n",
        "        –∏—Å–ø–æ–ª—å–∑—É—è —Ñ—É–Ω–∫—Ü–∏—é get_embeddings.\n",
        "\n",
        "    Args:\n",
        "        text (str): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
        "        tokenizer (RobertaTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –º–æ–¥–µ–ª–∏ RoBERTa.\n",
        "        model (RobertaModel): –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å RoBERTa.\n",
        "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU) –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–µ–∫—Å—Ç–∞.\n",
        "    \"\"\"\n",
        "    return get_embeddings(text, tokenizer, model, device)\n",
        "\n",
        "def process_long_text(text, tokenizer, model, device, chunk_size=512):\n",
        "    \"\"\"\n",
        "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–æ–π –±–æ–ª–µ–µ 512 —Ç–æ–∫–µ–Ω–æ–≤, —Ä–∞–∑–±–∏–≤–∞–µ—Ç –µ–≥–æ –Ω–∞ —á–∞–Ω–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n",
        "\n",
        "    Description:\n",
        "        –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–æ–π –±–æ–ª–µ–µ 512 —Ç–æ–∫–µ–Ω–æ–≤, —Ä–∞–∑–±–∏–≤–∞–µ—Ç –µ–≥–æ –Ω–∞ —á–∞–Ω–∫–∏,\n",
        "        —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –∫–∞–∂–¥—ã–π —á–∞–Ω–∫, –ø–æ–ª—É—á–∞–µ—Ç –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤.\n",
        "\n",
        "    Args:\n",
        "        text (str): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
        "        tokenizer (RobertaTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –º–æ–¥–µ–ª–∏ RoBERTa.\n",
        "        model (RobertaModel): –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å RoBERTa.\n",
        "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU) –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "        chunk_size (int): –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 512).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: –£—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–µ–∫—Å—Ç–∞.\n",
        "    \"\"\"\n",
        "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=False, padding=False)\n",
        "    input_ids = tokens[\"input_ids\"][0].tolist()\n",
        "\n",
        "    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏\n",
        "    chunks = [input_ids[i:i + chunk_size] for i in range(0, len(input_ids), chunk_size)]\n",
        "    embeddings = []\n",
        "    for chunk in chunks:\n",
        "        chunk_text = tokenizer.decode(chunk, skip_special_tokens=True)\n",
        "        emb = get_embeddings(chunk_text, tokenizer, model, device)\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    # –£—Å—Ä–µ–¥–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤\n",
        "    mean_embedding = torch.mean(torch.tensor(embeddings), dim=0).numpy()\n",
        "    return mean_embedding\n",
        "\n",
        "def process_dataframe(df, tokenizer, model, device):\n",
        "    \"\"\"\n",
        "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç DataFrame —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤—ã–π DataFrame —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏.\n",
        "\n",
        "    Description:\n",
        "        –§—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'text' –∏ 'toxic', –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π —Ç–µ–∫—Å—Ç,\n",
        "        –ø–æ–ª—É—á–∞—è –µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ RoBERTa. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –Ω–æ–≤—ã–π DataFrame —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏.\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): –í—Ö–æ–¥–Ω–æ–π DataFrame —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏.\n",
        "        tokenizer (RobertaTokenizer): –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä –º–æ–¥–µ–ª–∏ RoBERTa.\n",
        "        model (RobertaModel): –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å RoBERTa.\n",
        "        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU –∏–ª–∏ GPU) –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏.\n",
        "    \"\"\"\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['text']\n",
        "        label = row['toxic']\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö\n",
        "        tokenized_text = tokenizer(text)\n",
        "        if len(tokenized_text['input_ids']) <= 512:\n",
        "            embedding = process_short_text(text, tokenizer, model, device)\n",
        "        else:\n",
        "            embedding = process_long_text(text, tokenizer, model, device)\n",
        "\n",
        "        embeddings.append(embedding)\n",
        "        labels.append(label)\n",
        "\n",
        "    return pd.DataFrame({'embedding': embeddings, 'toxic': labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZvA2BuC2B1xs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-06-01T12:36:47.751436Z",
          "iopub.status.busy": "2024-06-01T12:36:47.750167Z",
          "iopub.status.idle": "2024-06-01T12:48:11.872893Z",
          "shell.execute_reply": "2024-06-01T12:48:11.871706Z",
          "shell.execute_reply.started": "2024-06-01T12:36:47.751386Z"
        },
        "id": "ZvA2BuC2B1xs",
        "outputId": "37f810c5-79ac-4b09-fca8-4e90dd7cf136",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (267 > 256). Running this sequence through the model will result in indexing errors\n",
            "2024-06-01 12:36:52.551183: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-01 12:36:57.031181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/tmp/ipykernel_6079/376032875.py:85: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  mean_embedding = torch.mean(torch.tensor(embeddings), dim=0).numpy()\n"
          ]
        }
      ],
      "source": [
        "# –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—É—á–∞—é—â–∏–π, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –∏ —Ç–µ—Å—Ç–æ–≤—ã–π –ø—É–ª –∏–∑ —ç–º–±–µ–Ω–¥–∏–Ω–≥–æ–≤\n",
        "embeddings_train = process_dataframe(df_train, tokenizer, bert, device = device)\n",
        "embeddings_val   = process_dataframe(df_valid, tokenizer, bert, device = device)\n",
        "embeddings_tst   = process_dataframe(df_test,  tokenizer, bert, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jogG7zVKDaJ1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:55:15.738536Z",
          "iopub.status.busy": "2024-06-01T12:55:15.737495Z",
          "iopub.status.idle": "2024-06-01T12:55:15.755104Z",
          "shell.execute_reply": "2024-06-01T12:55:15.754088Z",
          "shell.execute_reply.started": "2024-06-01T12:55:15.738484Z"
        },
        "id": "jogG7zVKDaJ1"
      },
      "outputs": [],
      "source": [
        "def process_embeddings(embeddings):\n",
        "    \"\"\"\n",
        "    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –º–µ—Ç–∫–∞–º–∏ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏.\n",
        "\n",
        "    –§—É–Ω–∫—Ü–∏—è –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
        "    1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ (X) –∏ –º–µ—Ç–∫–∏ (y).\n",
        "    2. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º StandardScaler.\n",
        "\n",
        "    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:\n",
        "    embeddings (pd.DataFrame): DataFrame, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Å—Ç–æ–ª–±—Ü—ã 'embedding' –∏ 'toxic'.\n",
        "\n",
        "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
        "    tuple: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (X) –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∫–∏ (y).\n",
        "    \"\"\"\n",
        "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ (X) –∏ –º–µ—Ç–∫–∏ (y)\n",
        "    X = np.vstack(embeddings['embedding'].values)\n",
        "    y = embeddings['toxic'].values\n",
        "\n",
        "    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WQzWkvVCYIgB",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T12:55:18.035568Z",
          "iopub.status.busy": "2024-06-01T12:55:18.033903Z",
          "iopub.status.idle": "2024-06-01T12:55:18.548698Z",
          "shell.execute_reply": "2024-06-01T12:55:18.547458Z",
          "shell.execute_reply.started": "2024-06-01T12:55:18.035507Z"
        },
        "id": "WQzWkvVCYIgB"
      },
      "outputs": [],
      "source": [
        "# –í–µ–∫—Ç–æ—Ä–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏\n",
        "X_train, y_train = process_embeddings(embeddings_train)\n",
        "X_val,   y_val   = process_embeddings(embeddings_val)\n",
        "X_test,  y_test  = process_embeddings(embeddings_tst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FyhmHrKLEshp",
      "metadata": {
        "id": "FyhmHrKLEshp"
      },
      "outputs": [],
      "source": [
        "# –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é SMOTE\n",
        "smote = SMOTE()\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
        "X_train_tensor = torch.tensor(X_res,  dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_res,  dtype=torch.long)\n",
        "X_val_tensor   = torch.tensor(X_val,  dtype=torch.float32)\n",
        "y_val_tensor   = torch.tensor(y_val,  dtype=torch.long)\n",
        "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor  = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–æ–≤\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset   = TensorDataset(X_val_tensor,   y_val_tensor)\n",
        "test_dataset  = TensorDataset(X_test_tensor,  y_test_tensor)\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ WeightedRandomSampler –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –º–∏–Ω–∏-–±–∞—Ç—á–µ–π\n",
        "class_sample_counts = torch.tensor([(y_train_tensor == t).sum() for t in torch.unique(y_train_tensor, sorted=True)])\n",
        "weights = 1. / class_sample_counts.float()\n",
        "samples_weights = weights[y_train_tensor]\n",
        "sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rhozto0vE6fJ",
      "metadata": {
        "id": "rhozto0vE6fJ"
      },
      "source": [
        "### –í—ã–≤–æ–¥\n",
        "\n",
        "–î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7vcrkkWQEl_T",
      "metadata": {
        "id": "7vcrkkWQEl_T"
      },
      "source": [
        "## **–≠—Ç–∞–ø 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zKFNKLTDHJkk",
      "metadata": {
        "id": "zKFNKLTDHJkk"
      },
      "outputs": [],
      "source": [
        "class ImprovedNN(nn.Module):\n",
        "    \"\"\"\n",
        "    –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ –±–∞—Ç—á–∞–º –∏ —Å–ª–æ—è–º–∏ Dropout.\n",
        "\n",
        "    –ê—Ç—Ä–∏–±—É—Ç—ã:\n",
        "    fc1, fc2, fc3, fc4, fc5 (nn.Linear): –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏.\n",
        "    bn1, bn2, bn3, bn4 (nn.BatchNorm1d): –°–ª–æ–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ –±–∞—Ç—á–∞–º.\n",
        "    relu1, relu2, relu3, relu4 (nn.LeakyReLU): –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ LeakyReLU.\n",
        "    dropout1, dropout2, dropout3, dropout4 (nn.Dropout): –°–ª–æ–∏ Dropout.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, num_classes):\n",
        "        \"\"\"\n",
        "        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–µ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏.\n",
        "\n",
        "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
        "        input_size   (int): –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è.\n",
        "        hidden_size1 (int): –†–∞–∑–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è.\n",
        "        hidden_size2 (int): –†–∞–∑–º–µ—Ä –≤—Ç–æ—Ä–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è.\n",
        "        hidden_size3 (int): –†–∞–∑–º–µ—Ä —Ç—Ä–µ—Ç—å–µ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è.\n",
        "        hidden_size4 (int): –†–∞–∑–º–µ—Ä —á–µ—Ç–≤–µ—Ä—Ç–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è.\n",
        "        num_classes ( int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–Ω–æ–º —Å–ª–æ–µ.\n",
        "        \"\"\"\n",
        "        super(ImprovedNN, self).__init__()\n",
        "\n",
        "        # –ü–µ—Ä–≤—ã–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∞—Ç—á–∞–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size1)\n",
        "        # –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LeakyReLU\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        # Dropout —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        # –í—Ç–æ—Ä–æ–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∞—Ç—á–∞–º –ø–æ—Å–ª–µ –≤—Ç–æ—Ä–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size2)\n",
        "        # –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LeakyReLU\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        # Dropout —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        # –¢—Ä–µ—Ç–∏–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∞—Ç—á–∞–º –ø–æ—Å–ª–µ —Ç—Ä–µ—Ç—å–µ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_size3)\n",
        "        # –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LeakyReLU\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        # Dropout —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "\n",
        "        # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
        "        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∞—Ç—á–∞–º –ø–æ—Å–ª–µ —á–µ—Ç–≤–µ—Ä—Ç–æ–≥–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–æ–≥–æ —Å–ª–æ—è\n",
        "        self.bn4 = nn.BatchNorm1d(hidden_size4)\n",
        "        # –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è LeakyReLU\n",
        "        self.relu4 = nn.LeakyReLU()\n",
        "        # Dropout —Å–ª–æ–π –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        # –í—ã—Ö–æ–¥–Ω–æ–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        self.fc5 = nn.Linear(hidden_size4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å.\n",
        "\n",
        "        –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
        "        x (torch.Tensor): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä.\n",
        "\n",
        "        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
        "        torch.Tensor: –í—ã—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä.\n",
        "        \"\"\"\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—ã–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π, –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –∏ Dropout\n",
        "        out = self.fc1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π, –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –∏ Dropout\n",
        "        out = self.fc2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Ç—Ä–µ—Ç–∏–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π, –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –∏ Dropout\n",
        "        out = self.fc3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.dropout3(out)\n",
        "\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —á–µ—Ç–≤–µ—Ä—Ç—ã–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π, –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –∏ Dropout\n",
        "        out = self.fc4(out)\n",
        "        out = self.bn4(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.dropout4(out)\n",
        "\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –≤—ã—Ö–æ–¥–Ω–æ–π –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π\n",
        "        out = self.fc5(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca68d03b-7bb3-45b7-abe1-86e6197d4552",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T13:41:36.806107Z",
          "iopub.status.busy": "2024-06-01T13:41:36.804833Z",
          "iopub.status.idle": "2024-06-01T13:43:50.923170Z",
          "shell.execute_reply": "2024-06-01T13:43:50.921887Z",
          "shell.execute_reply.started": "2024-06-01T13:41:36.806063Z"
        },
        "id": "ca68d03b-7bb3-45b7-abe1-86e6197d4552",
        "outputId": "514b91bc-9dd0-4bb3-ed4a-22fc9cb47595",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, F1-score (Validation): 0.8536589425208786\n",
            "Epoch 2, F1-score (Validation): 0.8760628481873568\n",
            "Epoch 3, F1-score (Validation): 0.8800009298146819\n",
            "Epoch 4, F1-score (Validation): 0.9237661518809585\n",
            "Epoch 5, F1-score (Validation): 0.9185714333051676\n",
            "Epoch 6, F1-score (Validation): 0.9340556123886334\n",
            "Epoch 7, F1-score (Validation): 0.924165483393463\n",
            "Epoch 8, F1-score (Validation): 0.9097840740834576\n",
            "Epoch 9, F1-score (Validation): 0.915647115600326\n",
            "Epoch 10, F1-score (Validation): 0.9381171483622351\n",
            "Epoch 11, F1-score (Validation): 0.9272098262545238\n",
            "Epoch 12, F1-score (Validation): 0.9159638798701301\n",
            "Epoch 13, F1-score (Validation): 0.9312409670774457\n",
            "Epoch 00013: reducing learning rate of group 0 to 5.0000e-05.\n",
            "Epoch 14, F1-score (Validation): 0.9290610524241385\n",
            "Epoch 15, F1-score (Validation): 0.9405868630743597\n",
            "Epoch 16, F1-score (Validation): 0.9296806201550387\n",
            "Epoch 17, F1-score (Validation): 0.9153843204209584\n",
            "Epoch 18, F1-score (Validation): 0.9326489620713456\n",
            "Epoch 19, F1-score (Validation): 0.9324044578447047\n",
            "Epoch 00019: reducing learning rate of group 0 to 2.5000e-05.\n",
            "Epoch 20, F1-score (Validation): 0.9381171483622351\n",
            "Epoch 21, F1-score (Validation): 0.9408372203381512\n",
            "Epoch 22, F1-score (Validation): 0.9273437188789303\n",
            "Epoch 23, F1-score (Validation): 0.930084397052139\n",
            "Epoch 24, F1-score (Validation): 0.9213739598037239\n",
            "Epoch 25, F1-score (Validation): 0.931863829720005\n",
            "Epoch 00025: reducing learning rate of group 0 to 1.2500e-05.\n",
            "Epoch 26, F1-score (Validation): 0.9390255582246887\n",
            "Epoch 27, F1-score (Validation): 0.9333260008380695\n",
            "Epoch 28, F1-score (Validation): 0.9285788573317406\n",
            "Epoch 29, F1-score (Validation): 0.9095995250917646\n",
            "Epoch 30, F1-score (Validation): 0.924858537806029\n",
            "Epoch 31, F1-score (Validation): 0.9372968612277217\n",
            "Epoch 00031: reducing learning rate of group 0 to 6.2500e-06.\n",
            "Early stopping triggered.\n",
            "--------------------------------------------------------------------------------\n",
            "Improved PyTorch –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å BatchNorm –∏ LeakyReLU –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
            "--------------------------------------------------------------------------------\n",
            "F1-score: 0.753441802252816\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96      5388\n",
            "           1       0.61      0.98      0.75       612\n",
            "\n",
            "    accuracy                           0.93      6000\n",
            "   macro avg       0.80      0.96      0.86      6000\n",
            "weighted avg       0.96      0.93      0.94      6000\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (GPU) –∏ –ø–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size = X_train.shape[1]\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 256\n",
        "hidden_size3 = 128\n",
        "hidden_size4 = 64\n",
        "num_classes = len(set(y_train))\n",
        "model = ImprovedNN(input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4, num_classes).to(device)\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º AdamW –∏ L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é\n",
        "\n",
        "# Scheduler –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è learning rate –Ω–∞ –ø–ª–∞—Ç–æ\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π\n",
        "best_f1_val = 0\n",
        "patience = 10\n",
        "trigger_times = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
        "        outputs = model(X_batch)\n",
        "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # –û–±–Ω—É–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤\n",
        "        optimizer.zero_grad()\n",
        "        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ\n",
        "        loss.backward()\n",
        "        # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
        "        optimizer.step()\n",
        "\n",
        "    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
        "    model.eval()\n",
        "    val_outputs = []\n",
        "    val_labels = []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
        "            outputs = model(X_batch)\n",
        "            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_outputs.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "    # –†–∞—Å—á–µ—Ç F1-score –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
        "    current_f1_val = f1_score(val_labels, val_outputs, average='weighted')\n",
        "    print(f\"Epoch {epoch + 1}, F1-score (Validation): {current_f1_val}\")\n",
        "\n",
        "    # –®–∞–≥ scheduler\n",
        "    scheduler.step(loss)\n",
        "\n",
        "    if current_f1_val > best_f1_val:\n",
        "        best_f1_val = current_f1_val\n",
        "        trigger_times = 0\n",
        "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print('Early stopping triggered.')\n",
        "            break\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\n",
        "model.eval()\n",
        "\n",
        "# –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
        "val_outputs = []\n",
        "val_labels = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in val_loader:\n",
        "        # –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥\n",
        "        outputs = model(X_batch)\n",
        "        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        val_outputs.extend(preds.cpu().numpy())\n",
        "        val_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\n",
        "print_with_lines(\"Improved PyTorch –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å BatchNorm –∏ LeakyReLU –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ\", y_val, val_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dGA6taTbJ5LL",
      "metadata": {
        "id": "dGA6taTbJ5LL"
      },
      "source": [
        "## **–≠—Ç–∞–ø 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52499a74-4cac-45f7-9d92-4aae64d7b4cf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-01T13:44:04.052967Z",
          "iopub.status.busy": "2024-06-01T13:44:04.051514Z",
          "iopub.status.idle": "2024-06-01T13:44:04.409Z",
          "shell.execute_reply": "2024-06-01T13:44:04.407818Z",
          "shell.execute_reply.started": "2024-06-01T13:44:04.052915Z"
        },
        "id": "52499a74-4cac-45f7-9d92-4aae64d7b4cf",
        "outputId": "8e6fadbd-bdc4-4531-9208-7309bfec2442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Improved PyTorch –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å BatchNorm –∏ LeakyReLU –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\n",
            "--------------------------------------------------------------------------------\n",
            "F1-score: 0.7392739273927392\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96      5432\n",
            "           1       0.59      0.99      0.74       568\n",
            "\n",
            "    accuracy                           0.93      6000\n",
            "   macro avg       0.79      0.96      0.85      6000\n",
            "weighted avg       0.96      0.93      0.94      6000\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\n",
        "test_outputs = []\n",
        "test_labels = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_outputs.extend(preds.cpu().numpy())\n",
        "        test_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "print_with_lines(\"Improved PyTorch –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å BatchNorm –∏ LeakyReLU –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ\", y_test, test_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hK6Z6FlWt5Xi",
      "metadata": {
        "id": "hK6Z6FlWt5Xi"
      },
      "source": [
        "–ü–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω–æ, –¥—É–º–∞—é, —á—Ç–æ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∏ —Ç–∞–∫."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vy_9QBpfFXzk",
      "metadata": {
        "id": "vy_9QBpfFXzk"
      },
      "source": [
        "### **–í—ã–≤–æ–¥**\n",
        "\n",
        "–ë—ã–ª–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –Ω–∞ –∑–∞–¥–∞—á–µ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyTorch. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –≤–∫–ª—é—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–ª–æ–µ–≤ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø–æ –±–∞—Ç—á–∞–º, —Å–ª–æ—è–º–∏ Dropout –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ LeakyReLU –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.\n",
        "\n",
        "–ú–æ–¥–µ–ª—å –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º–∞ AdamW –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ L2. –¢–∞–∫–∂–µ –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –º–µ—Ö–∞–Ω–∏–∑–º —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ —Å–Ω–∏–∂–µ–Ω–∏–µ learning rate –Ω–∞ –ø–ª–∞—Ç–æ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –Ω–∞–∏–ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.\n",
        "\n",
        "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –∏ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –ø–æ–∫–∞–∑–∞–ª–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
        "\n",
        "- F1-score –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ: 0.75\n",
        "- F1-score –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ: 0.74\n",
        "\n",
        "–≠—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —É—Å–ª–æ–≤–∏—è–º –∑–∞–¥–∞—á–∏, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—è, —á—Ç–æ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è F1-score. –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç—â–∞—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∑–≤–æ–ª–∏–ª–∏ –¥–æ—Å—Ç–∏—á—å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.\n"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 4069,
        "start_time": "2024-06-01T02:38:28.412Z"
      },
      {
        "duration": 9406,
        "start_time": "2024-06-01T02:38:32.483Z"
      },
      {
        "duration": 1017,
        "start_time": "2024-06-01T02:38:41.891Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.911Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.915Z"
      },
      {
        "duration": 1,
        "start_time": "2024-06-01T02:38:42.915Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.916Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.917Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.917Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.918Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.918Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.965Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.967Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.968Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.970Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.972Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.974Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.975Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.977Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.978Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.979Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.980Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.981Z"
      },
      {
        "duration": 0,
        "start_time": "2024-06-01T02:38:42.983Z"
      },
      {
        "duration": 3691,
        "start_time": "2024-06-01T12:06:30.426Z"
      },
      {
        "duration": 11747,
        "start_time": "2024-06-01T12:06:43.261Z"
      }
    ],
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}